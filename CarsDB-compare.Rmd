---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.1.3
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Compare results in the DB

```{python}
## To autoreload codein python files here.
# %load_ext autoreload
# %autoreload 2

## Add %%black at the top of a cell, and re-evaluate it, 
# to format it before git-commits, and ease diffs.
# %load_ext blackcellmagic
```

```{python}
from typing import Union, List, Callable, Any, Sequence as Seq
import io
import logging
from pathlib import PurePosixPath as P


import numpy as np
import pandas as pd
from pandas import HDFStore
from pandas.core.generic import NDFrame
from matplotlib import pyplot as plt
import qgrid
from wltp.experiment import Experiment
from ruamel.yaml import YAML

import nbutils as nbu

idx = pd.IndexSlice
log = logging.getLogger('CarsDB-compare.ipynb')
logging.basicConfig(level=logging.INFO)
```

```{python}
## DEFINITIONS
#
h5fname = 'WltpCars.h5'
c_n, c_p, c_n_norm, c_p_norm = 'n', 'Pwot', 'n_norm', 'p_norm'
```

```{python}
a=nbu.print_nodes(h5fname);
```

```{python}
def vehgroups_with_out1(g):
    return g.endswith('out1') and str(P(g).parent)

## Find VEHICLES without RESULT
#
hasv: List[int] = [int(n[len('/vehicles/v'):]) for n in nbu.collect_nodes(h5fname, vehgroups_with_out1)]
misv: List[int] = sorted(set(range(1, 116)) - set(hasv))
print(', '.join('%s' % i for i in misv))

# import random
# random.choices(misv, k=9)
```

```{python}
## Merge vehicles into Indexed Pandas
#
def merge_veh_datasets(h5: Union[str, HDFStore], data_subgroups, nodes_predicate) -> List[NDFrame]:
    def func(h5db):
        veh_groups = nbu.collect_nodes(h5db, nodes_predicate)
        data_collected = list(
            zip(
                *(
                    tuple( 
                        (vehg, h5db.get(str(P(vehg) / datag)))  # key: vehnum, value: subgroup-dfs
                        for datag in data_subgroups
                    )
                    for vehg in veh_groups
                )
            )
        )
        
        return data_collected
    data_collected = nbu.do_h5(h5, func)


    dicts_to_merge = [dict(d) for d in data_collected]
    index_dfs = [pd.concat(d.values(), keys=d.keys()).sort_index() for d in dicts_to_merge]

    return index_dfs
 
datags_to_collect = ("out1/props", "out1/cycle", "out2/props", "out2/cycle")

p1, c1, p2, c2 = merge_veh_datasets(h5fname, datags_to_collect, vehgroups_with_out1)
```

```{python}
cmpr = nbu.Comparator(lambda d, c: d.loc[idx[:, c]])
dataset_names = "Heinz Phase1a".split()
```

```{python}
## Report PROP differences
#
equivalent_columns = [("p_downscale", "f_downscale"), ("cycle", "wltc_class")]

display(
    cmpr.compare((p1, p2), equivalent_columns, dataset_names),
    qgrid.show_grid(p1),
    qgrid.show_grid(p2),
)
```

```{python}
## Report CYCLE-MEAN differences
#
cols1 = ["v_orig", "v in km/h", "gear", "g_min", "P_res in kW", "Pavailable in kW", "n in min-1"]
cols2 = ["v_class", "v_target", "gears_orig", "gears", "p_required", "p_available", "rpm"]
cc1 = c1[cols1].mean(level=0)
cc2 = c2[cols2].mean(level=0)

equivalent_columns = list(zip(cols1, cols2))
display(
    cmpr.compare((cc1, cc2), equivalent_columns, dataset_names),
    c1.columns,
    c2.columns,
    qgrid.show_grid(c1), 
    qgrid.show_grid(c2),
)
```
