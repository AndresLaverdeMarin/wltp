---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.1.3
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Parse excel files into a HDF5 file
It builds an an [HDF5 file](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-hdf5) 
with the the *vehicle inputs (`props`, `pwot`) & *outputs* from Heinz MSAccess DB.

## To see the full tree
...check the `README.py`,
## to run this notebook in your own jupyter-server
...read instructions on the `README.md`,
## to inspect and get help on the HDF5 file
...read instructions on the `README.md` and consult the `HDF5-API.ipynb` notebook.

```{python}
## To autoreload codein python files here.
# %load_ext autoreload
# %autoreload 2

## Add %%black at the top of a cell, and re-evaluate it, 
# to format it before git-commits, and ease diffs.
# %load_ext blackcellmagic
```

```{python}
import functools as ftt
import itertools as itt
import logging
from pathlib import Path
import re
from typing import Tuple, Dict

import numpy as np
from pandalone import xleash
import qgrid
import pandas as pd
from pandas import HDFStore

import nbutils as nbu

idx = pd.IndexSlice
log = logging.getLogger('CarsDB-inputs.ipynb')
logging.basicConfig(level=logging.INFO)
```

```{python}
## DEFINITIONS
#
h5fname = 'WltpCars.h5'
# Test cars delivered by Heinz on 13 May 2019
heinzdb_fpath="WLTP_GS_calculation_15032019_for_prog_code_subgroup.accdb"
xlfname = Path("example vehicles for the prog code validation.xlsx")
c_vehnum, c_n, c_pwot, c_SM, c_ASM = 'vehicle_no', 'n', 'Pwot', 'SM', 'ASM'
```

```{python}
## PROVENANCE: discover how it came to be, at a later time
#  (might take 10'')
root_prov_info = nbu.provenance_info(files=[heinzdb_fpath], repos=['.']) 
```

```{python}
## UNCOMMENT next command & run to DELETE the db-file, and rebuild it.
# !rm {h5fname}
```

```{python}
nbu.print_nodes(h5fname)
```

```{python}
from pandalone import xleash

specs = xleash.lasso('%s#technical data!::["df"]' % xlfname)
pwots = xleash.lasso('%s#wot power curves!::["df"]' % xlfname)
```

```{python}
import qgrid

display(qgrid.show_grid(specs))
display(qgrid.show_grid(pwots))
```

```{python}
def extract_SM_from_pwot(
    pwot, c_n=c_n, c_pwot=c_pwot, c_SM=c_SM, c_ASM=c_ASM
) -> "Tuple(pd.DataFrame, float)":
    """
    Keep just (n, Pwot, ASM) columns & extract SM column as scalar value.
    
    :param pwot:
        the wot-curve for a single vehicle, a df like::
        
            IX	vehicle_no	n	Pwot	SM	ASM
            -----------------------
            0	1			800	5.43	0.1	0.0
            0	1			900	9.01	0.1	0.0
    :return:
        wot(n: pwot, ASM), SM
        where `wot` is indexed by engine-speed(n)
    """
    SM = nbu.get_scalar_column(pwot, c_SM)
    pwot = pwot.loc[:, [c_n, c_pwot, c_ASM]].set_index(c_n)

    return pwot, SM


# ## TEST
# extract_SM_from_pwot(pwots.loc[pwots[c_vehnum] == 3])
```

```{python}
# Store each a vehicle into a node with 2 nodes: props, pwot
#
base = nbu.provenance_info(files=[xlfname], base=root_prov_info)


def store_group_per_car(h5db, specs, c_vehnum=c_vehnum, c_SM=c_SM, c_ASM=c_ASM):
    for _, spec in specs.iterrows():
        vehnum = spec[c_vehnum]
        spec_node = nbu.vehnode(vehnum, "props")
        pwot_node = nbu.vehnode(vehnum, "pwot")

        pwot = pwots.loc[pwots[c_vehnum] == vehnum, :]
        pwot, SM = extract_SM_from_pwot(pwot)

        spec[c_SM] = SM

        h5db.put(spec_node, spec)
        h5db.put(pwot_node, pwot)

        nbu.provenir_h5node(
            h5db,
            spec_node,
            title="Specs of the test-car, as delivered by Heinz on 13 May 2019",
            base=base,
        )
        nbu.provenir_h5node(
            h5db,
            pwot_node,
            title="Full-load-curve of the test-car, as delivered by Heinz on 13 May 2019",
            base=base,
        )


with nbu.openh5(h5fname) as h5db:
    store_group_per_car(h5db, specs)
    nbu.provenir_h5node(
        h5db,
        nbu.vehnode(),
        title="preprocessed cars for python consumption",
        base=base,
    )
```

```{python}
def fpath_to_vehnum(outfpath: Path) -> int:
    """
    Parse the folder-path containing the HeinzDb result excel files
    
        vehicles/
            +--v001/
            |   +--props          ADD: (series) all kv-pairs from input/specs + SM, ASM
            |   +--pwot           ADD: (df) a single-column df(wot) indexed by n
    """
    import re

    return int(re.match(r"V(\d+)\.xls", outfpath.name).group(1))


base = nbu.provenance_info(base=root_prov_info)
scalar_columns = [
    "Calculation date",
    "Time at calculation start",
    "Version",
    "cycle_type",
    "cycle",
    "cycle_chosen_by_user",
    "vehicle_no",
    "vehicle",
    "vehicle_class",
    "kerb_mass in kg",
    "test_mass in kg",
    "rated power in kW",
    "rated_speed in min-1",
    "idling_speed in min-1",
    "n_min_drive_set",
    "n_min_drive_up",
    "n_min_drive_up_modified",
    "n_min_drive_down",
    "n_min_drive_down_modified",
    "n_min_drive_start_up",
    "n_min_drive_start_down",
    "t_end_start_phase",
    "n_min_drive_start_applied",
    "no_of_gears",
    "gear_v_max",
    "v_max_declared",
    "v_max_calculated",
    "f0",
    "f1",
    "f2",
    "speed cap in km/h",
    "p_downscale",
    "downscaling",
    "suppress gear 0 during downshifts",
    "n_max1",
    "n_max2",
    "n95_low",
    "n95_high",
    "average_gear",
]


def store_results_per_car(
    h5db,
    results_dir="VehResults",
    cycle_group_suffix="out1/cycle",
    props_group_suffix="out1/props",
):
    """
    Populate h5db with results collected from a folder full of (`V123.xls`, ...) exchel-files.
    
        vehicles/
            +--v001/
            |   +--props
            |   +--pwot
            |   +--out1
            |       +--cycle      ADD: (df) cycle-run generated by HeinzDb
            |       +--props      ADD: (series) scalar inputs & outputs generated by HeinzDb
            ...
    """

    # A dir with one Excel-file per vehicle, as produced by MSAccess.
    results_dir = Path(results_dir)
    for outfpath in results_dir.glob("*.xls"):
        vehnum = fpath_to_vehnum(outfpath)

        outdf = xleash.lasso('%s#::["df"]' % outfpath)
        outdf, props = nbu.drop_scalar_columns(outdf, scalar_columns)

        cycle_group = nbu.vehnode(vehnum, cycle_group_suffix)
        h5db.put(cycle_group, outdf)
        nbu.provenir_h5node(
            h5db,
            cycle_group,
            files=[outfpath],
            title="Cycle-run produced by Heinz's MSAccess db",
            base=base,
        )

        props_group = nbu.vehnode(vehnum, props_group_suffix)
        h5db.put(props_group, pd.Series(props))
        nbu.provenir_h5node(
            h5db,
            props_group,
            files=[outfpath],
            title="Properties (in & out) produced by Heinz's MSAccess db",
            base=base,
        )


with nbu.openh5(h5fname) as h5db:
    store_results_per_car(h5db)
```

```{python}
nbu.print_nodes(h5fname)
```

```{python}
# %%time
## COMPRESS x100 HDF5: 122MB --> ~3.1MB in 5.6s on my speedy laptop.
#
# !ls -lh {h5fname}
# !ptrepack  {h5fname}  --complevel=9 --complib=blosc:blosclz -o {h5fname}.tmp
# !mv  {h5fname}.tmp {h5fname}
# !ls -lh {h5fname}
```

```{python}
## Printout all vehicle data
#
inpsr, outdf, outsr = nbu.load_vehicle(h5fname, 14, 'props', 'out1/cycle', 'out1/props')
display(inpsr, outsr, outdf.columns, qgrid.show_grid(outdf, grid_options={'forceFitColumns': False}))
```
