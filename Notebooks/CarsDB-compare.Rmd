---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.1.7-rc0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Compare results in the DB

```{python}
## To autoreload codein python files here.
# %load_ext autoreload
# %autoreload 2

## Add %%black at the top of a cell, and re-evaluate it, 
# to format it before git-commits, and ease diffs.
# %load_ext blackcellmagic
```

```{python}
from typing import Union, List, Callable, Any, Sequence as Seq
import io
import logging
from pathlib import PurePosixPath as P


from columnize import columnize
import numpy as np
import pandas as pd
from pandas import HDFStore
from pandas.core.generic import NDFrame
from matplotlib import pyplot as plt
import qgrid
from wltp.experiment import Experiment

import nbutils as nbu

idx = pd.IndexSlice
log = logging.getLogger('CarsDB-compare.ipynb')
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s|%(levelname)4.4s|%(module)s:[%(funcName)s]:\n  +--> %(message)s', 
    datefmt='%Y-%m-%d,%H:%M:%S',
)
```

```{python}
## DEFINITIONS
#
inp_h5fname = 'VehData/WltpGS-msaccess.h5'
out_h5fname = 'VehData/WltpGS-python.h5'
c_n, c_p, c_n_norm, c_p_norm = 'n', 'Pwot', 'n_norm', 'p_norm'
```

```{python}
nbu.print_nodes(inp_h5fname)
nbu.print_nodes(out_h5fname)
```

```{python}
def merge_veh_datasets(h5: Union[str, HDFStore], data_subgroups) -> List[NDFrame]:
    """
    Merge HDF-subgroup(s) from all vehiclesinto an Indexed-DataFrame(s)

    :return:
        as may merged-dataframes as `data_subgroups` given
    """

    def func(h5db):
        vehnums = nbu.all_vehnums(h5db)
        data_collected = list(
            zip(
                *(
                    tuple(
                        # key: vehnum, value: subgroup-dfs
                        ("v%0.3i" % vehnum, h5db.get(nbu.vehnode(vehnum, datag)))
                        for datag in data_subgroups
                    )
                    for vehnum in vehnums
                )
            )
        )

        return data_collected

    data_collected = nbu.do_h5(h5, func)

    dicts_to_merge = [dict(d) for d in data_collected]
    index_dfs = [
        pd.concat(d.values(), keys=d.keys()).sort_index() for d in dicts_to_merge
    ]

    return index_dfs


ip1, p1, c1 = merge_veh_datasets(inp_h5fname, ("iprop", "oprop", "cycle"))
p2, c2 = merge_veh_datasets(out_h5fname, ("oprop", "cycle"))

## Merge input & Output props from heinz db.
#
ip1.name, p1.name = "ab"  # da butare
p1 = pd.concat((ip1, p1), axis=0).sort_index()
p1 = p1[~p1.index.duplicated()]  # or else, pivot(unstack) fails below

## By the spec, V rounded to 2-digits,
#  But exporting MSAccess --> Excel outputs garbage decimals!
#
v_cols = "v v_orig v_cap v_downscale".split()
c1[v_cols] = c1[v_cols].round(1)
```

```{python}
display(
    nbu.grid(p1),
    nbu.grid(p2),
    #nbu.grid(c1, fitcols=0),
)
```

```{python}
sr_cmpr = nbu.Comparator(lambda d, c: d[:, c], no_styling=True)
dataset_names = "Heinz Python".split()
```

```{python}
## Report PROP differences
#
equivalent_columns = [
    ("Description", None),
    ("class", "wltc_class"),
    ("pmr_km", "pmr"),
    ("f_dsc_req", "f_downscale"),
    ("test_mass", "test_mass"),
    ("kerb_mass", "unladen_mass"),
    ("v_max", "v_max")
]

cdf = sr_cmpr.compare((p1, p2), equivalent_columns, dataset_names)
## Workaround qgrid's hate for hierarchical-columns:
#  https://github.com/quantopian/qgrid/issues/18#issuecomment-149321165
cdf.columns = [' '.join(col).strip() for col in cdf.columns.values]

display(nbu.grid(cdf, fitcols=False, cwidth=100),)
```

```{python}
print(columnize(list(c1.columns), displaywidth=160))
print(c2.columns)
```

```{python}
cmpr = nbu.Comparator(lambda d, c: d.loc[idx[:, c]])
```

```{python}
## Report CYCLE-MEAN differences
#
cols1 = ["v_orig", "a_orig", "v", "g_max", "gear", "P_tot", "P_max", "n_kl"]
cols2 = ["v_class", "a_class", "v_target", "gears_orig", "gears", "p_required", "p_available", "rpm"]
cc1 = pd.concat((p1.unstack(), c1[cols1].mean(level=0)), axis=1)
cc2 = pd.concat((p2.unstack(), c2[cols2].mean(level=0)), axis=1)

## Convert props to numerics 
cc1[cols1 + ["pmr_km", "f_dsc_req"]] = cc1[cols1 + ["pmr_km", "f_dsc_req"]].astype('float64')
cc2[cols2 + ["f_downscale"]] = cc2[cols2 + ["f_downscale"]].astype('float64')

equivalent_columns = [
    ("Description", None),
    ("class", None),
    ("pmr_km", None),
    ("f_dsc_req", "f_downscale"),
]
equivalent_columns += list(zip(cols1, cols2))
display(
    cmpr.compare((cc1, cc2), equivalent_columns, dataset_names),
)
```

```{python}
import wltp.plots as wp


def plot_xy_diffs_arrows(
    df: pd.DataFrame,
    cols_x1y1x2y2: Seq[str],
    data_label,
    ref_label=None,
    data_fmt="+k",
    data_kws={},
    diff_label=None,
    diff_fmt="-r",
    diff_cmap=wp.cm.hsv,
    diff_kws={},  # @UndefinedVariable cm.PiYG
    title=None,
    x_label=None,
    y_label=None,
    axes_tuple=None,
    mark_sections=None,
    distance_prcnt_threshold=1,
):
    # fix data: np.sqrt() works only on float64, and
    # indexing duped columns fetches df (not series). 
    df = df[set(cols_x1y1x2y2)].astype(np.float64)
    X_REF, Y_REF, X, Y = [df[i] for i in cols_x1y1x2y2]
    
    df['Xdiff'] = X - X_REF
    df['Ydiff'] = Y - Y_REF
    
    # Filter out small differences.
    #
    df['dist_x'] = df['Xdiff'].abs() / X_REF
    df['dist_y'] = df['Ydiff'].abs() / Y_REF
    df['dist_max[%]'] = df[['dist_x', 'dist_y']].max(axis=1) * 100
    df = df.loc[df['dist_max[%]'] > distance_prcnt_threshold, :]

    X_REF, Y_REF, X, Y = [df[i] for i in cols_x1y1x2y2]
    U = df['Xdiff']
    V = df['Ydiff']

    ANGLE = phi = np.arctan2(V, U)

    color_diff = "r"
    alpha = 0.9
    cm_norm = wp.MidPointNorm()

    if axes_tuple:
        (axes, twin_axis) = axes_tuple
    else:
        bottom = 0.1
        height = 0.8
        axes = plt.axes([0.1, bottom, 0.80, height])

        ## Prepare axes
        #
        axes.set_xlabel(x_label)
        axes.set_ylabel(r"$%s$" % y_label.replace("$", ""))
        axes.xaxis.grid(True)
        axes.yaxis.grid(True)

        twin_axis = axes.twinx()
        twin_axis.set_ylabel(
            r"$\Delta %s$" % y_label.replace("$", ""), color=color_diff, labelpad=0
        )
        twin_axis.tick_params(axis="y", colors=color_diff)
        twin_axis.yaxis.grid(True, color=color_diff)

        axes.set_title(title)
        axes_tuple = (axes, twin_axis)

    if mark_sections == "classes":
        plot_class_limits(axes, Y.min())
    elif mark_sections == "parts":
        raise NotImplementedError()

    ## Plot data
    #
    l_ref = axes.quiver(
        X,
        Y,
        U,
        V,
        ANGLE,
        cmap=diff_cmap,
        norm=cm_norm,
        scale_units="xy",
        angles="xy",
        scale=1,
        width=0.004,
        alpha=alpha,
        pivot="tip",
    )

    l_data, = axes.plot(X, Y, data_fmt, label=data_label, **data_kws)
    l_data.set_picker(3)

    l_diff = twin_axis.plot(X, V, "o", color=color_diff, markersize=0.7)
    line_points, regress_poly = wp.fit_straight_line(X, V)
    l_diff_fitted, = twin_axis.plot(
        line_points,
        wp.polyval(regress_poly, line_points),
        diff_fmt,
        label=diff_label,
        **diff_kws
    )

    for name, x, y in zip(Y.index, X_REF, Y_REF):
        axes.annotate(name, (x, y), xycoords="data", size='xx-small')

    return axes_tuple, (l_data, l_ref, l_diff, l_diff_fitted)
```

```{python}
# %matplotlib widget

plt.close(); plt.figure()
plot_xy_diffs_arrows(pd.concat((cc1, cc2), axis=1), cols_x1y1x2y2=['pmr_km', "n_kl", 'pmr', 'rpm'], 
                     data_label="n in min-1", ref_label="HeinzDb",
#             data_fmt="+k", data_kws={},
#             diff_label=None, diff_fmt="-r", diff_cmap=cm.hsv, diff_kws={}, #@UndefinedVariable cm.PiYG
#             title='N', 
                     x_label='PMR', 
                     y_label='N_mean',
#             axes_tuple=None,
#             mark_sections=None
                    )
```

```{python}
plt.close(); plt.figure()
veh = 'v078'
display(c1.loc[veh, 'v'].mean(), c2.loc[veh, 'v_class'].mean())
ax = c1.loc[veh, 'v'].plot()
c2.loc[veh, 'v_class'].plot()
```
