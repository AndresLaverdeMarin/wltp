---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.1.7-rc0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Populate DB with python-code's results
It builds an an [HDF5 file](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-hdf5) 
with the *outputs* (`oprop`, `cycle`) from this *wltp* library.

```{python}
## To autoreload codein python files here.
# %load_ext autoreload
# %autoreload 2

## Add %%black at the top of a cell, and re-evaluate it, 
# to format it before git-commits, and ease diffs.
# %load_ext blackcellmagic
```

```{python}
from typing import Union
import io
import logging
from pathlib import Path, PurePosixPath as P

import pandas as pd
from wltp.experiment import Experiment
import wltp.utils as wutils

import nbutils as nbu

log = logging.getLogger('CarsDB-phase1a.ipynb')
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s|%(levelname)4.4s|%(module)s:[%(funcName)s]:\n  +--> %(message)s', 
    datefmt='%Y-%m-%d,%H:%M:%S',
)
```

```{python}
## DEFINITIONS
#
inp_h5fname = 'VehData/WltpGS-msaccess.h5'
out_h5fname = 'VehData/WltpGS-python.h5'
# Test cars delivered by Heinz to ank on 4 Jun 2019
heinzdb_fpath="VehData/WLTP_GS_calculation_28052019-116cars.accdb"
xlfname = Path("VehData/vehicle_info-116.xlsx")
c_n, c_p, c_n_norm, c_p_norm = 'n', 'Pwot', 'n_norm', 'p_norm'
```

```{python}
## PROVENANCE: discover how it came to be, at a later time
#  (might take 10'')
root_prov_info = nbu.provenance_info(files=[heinzdb_fpath], repos=['.', '../wltp.git']) 
```

```{python}
## UNCOMMENT next command & run to DELETE the db-file, and rebuild it.
# !rm -f {out_h5fname}
```

```{python}
nbu.print_nodes(out_h5fname)
```

```{python}
def normalize_pwot(
    pwot,
    n_idle,
    n_rated,
    p_rated,
    c_n=c_n,
    c_p=c_p,
    c_n_norm=c_n_norm,
    c_p_norm=c_p_norm,
):
    pwot = pwot.copy()
    pwot[c_n] = pwot.index
    
    pwot[c_n_norm] = (pwot[c_n] - n_idle) / (n_rated  - n_idle)
    pwot[c_p_norm] = pwot[c_p] / p_rated
    
    return pwot[[c_n_norm, c_p_norm]]
```

```{python}
def run_python_wltp_on_db_vehice(h5, vehnum, 
                                 props_group_suffix="iprop", pwot_group_suffix="pwot"):
    "Quick'n dirty way to invoke python-algo."
    
    props, pwot = nbu.load_vehicle(h5, vehnum, props_group_suffix, pwot_group_suffix)

    ndvs = [props["ndv_%i" % g] for g in range(1, props["no_of_gears"] + 1)]
    norm_pwot = normalize_pwot(
        pwot, props.idling_speed, props.rated_speed, props.rated_power
    )
    inverse_SM = 1.0 - props.SM

    input_model = wutils.yaml_loads(
        f"""
        vehicle:
          gear_ratios:  {ndvs}
          resistance_coeffs:
            - {props.f0} 
            - {props.f1}
            - {props.f2}
          p_rated:      {props.rated_power}
          unladen_mass: {props.kerb_mass}
          test_mass:    {props.test_mass}
          n_rated:      {props.rated_speed}
          n_idle:       {props.idling_speed}
          v_max:        {props.v_max_declared}
        params:
          f_safety_margin: {inverse_SM}
        """
    )
    input_model["vehicle"]["full_load_curve"] = norm_pwot

    exp = Experiment(input_model)
    output_model = exp.run()

    veh = output_model['vehicle']
    ## Include also the only out-value in params.
    veh['f_downscale'] = output_model['params']['f_downscale']
    ## Drop these arrays not to burden HDF data-model
    #  (all but `, exist also in inputs.
    #
    del veh['resistance_coeffs'], veh['gear_ratios']
    output_model['cycle_run'] = output_model['cycle_run'].drop('driveability', axis=1)
    
    return output_model
# output_model = run_python_wltp_on_db_vehice(inp_h5fname, 14)
# display(output_model["cycle_run"])
```

```{python}
def store_python_results(
    inph5, outh5, props_group_suffix="oprop", cycle_group_suffix="cycle", no_write=False
):
    """
    RUN PYTHON on cars that have HeinzDB results in /vechicles/v123/out1
    
    and build:
    
        vehicles/
            +--v001/
            |   +--oprop      ADD: (series) scalars generated by python-algo
            |   +--cycle      ADD: (df) cycle-run generated by python-alog
            +...
            
    """

    def run_vehicles_with_pythons(h5db):
        for vehnum in nbu.all_vehnums(h5db):
            try:
                yield vehnum, run_python_wltp_on_db_vehice(inph5, vehnum)
            except Exception as ex:
                log.error("V%0.3i failed: %s", vehnum, ex)
                raise ex
    
    def store_vehicles(h5db, vehnum, outmodel):
        if no_write:
            return
        g = nbu.vehnode(vehnum, props_group_suffix)
        h5db.put(g, pd.Series(outmodel["vehicle"]))
        nbu.provenir_h5node(
            h5db,
            g,
            title="Wltp-run generated old pghase-1a python",
            base=root_prov_info,
        )

        g = nbu.vehnode(vehnum, cycle_group_suffix)
        h5db.put(g, outmodel["cycle_run"])
        nbu.provenir_h5node(
            h5db,
            g,
            title="Wltp-run generated old phase-1a python",
            base=root_prov_info,
        )

    
    for vehnum, outmodel in nbu.do_h5(inph5, run_vehicles_with_pythons):
        nbu.do_h5(outh5, store_vehicles, vehnum, outmodel)

with nbu.openh5(inp_h5fname) as inph5, nbu.openh5(out_h5fname) as outh5:
    store_python_results(inph5, outh5)
```

```{python}
nbu.print_nodes(out_h5fname)
```

```{python}
# %%time
## COMPRESS x100 HDF5: 135Mb-->19Mb in 22s.
#
# !ls -lh {out_h5fname}
# !ptrepack  {out_h5fname}  --complevel=9 --complib=blosc:blosclz -o {out_h5fname}.tmp
# !mv  {out_h5fname}.tmp {out_h5fname}
# !ls -lh {out_h5fname}
```
